-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
-- Need to be super user to create extension and add data nodes
\c :TEST_DBNAME :ROLE_CLUSTER_SUPERUSER;
\unset ECHO
psql:include/filter_exec.sql:5: NOTICE:  schema "test" already exists, skipping
psql:include/remote_exec.sql:5: NOTICE:  schema "test" already exists, skipping
\set DATA_NODE_1 :TEST_DBNAME _1
\set DATA_NODE_2 :TEST_DBNAME _2
\set DATA_NODE_3 :TEST_DBNAME _3
\set DATA_NODE_4 :TEST_DBNAME _4
\set TABLESPACE_1 :TEST_DBNAME _1
\set TABLESPACE_2 :TEST_DBNAME _2
SELECT
    test.make_tablespace_path(:'TEST_TABLESPACE1_PREFIX', :'TEST_DBNAME') AS spc1path,
    test.make_tablespace_path(:'TEST_TABLESPACE2_PREFIX', :'TEST_DBNAME') AS spc2path
\gset
SELECT node_name, database, node_created, database_created, extension_created
FROM (
  SELECT (add_data_node(name, host => 'localhost', DATABASE => name)).*
  FROM (VALUES (:'DATA_NODE_1'), (:'DATA_NODE_2'), (:'DATA_NODE_3')) v(name)
) a;
      node_name       |       database       | node_created | database_created | extension_created 
----------------------+----------------------+--------------+------------------+-------------------
 db_dist_hypertable_1 | db_dist_hypertable_1 | t            | t                | t
 db_dist_hypertable_2 | db_dist_hypertable_2 | t            | t                | t
 db_dist_hypertable_3 | db_dist_hypertable_3 | t            | t                | t
(3 rows)

GRANT USAGE ON FOREIGN SERVER :DATA_NODE_1, :DATA_NODE_2, :DATA_NODE_3 TO PUBLIC;
-- View to see dimension partitions. Note RIGHT JOIN to see that
-- dimension partitions are cleaned up (deleted) properly.
CREATE VIEW hypertable_partitions AS
SELECT table_name, dimension_id, range_start, data_nodes
FROM _timescaledb_catalog.hypertable h
INNER JOIN _timescaledb_catalog.dimension d ON (d.hypertable_id = h.id)
RIGHT JOIN _timescaledb_catalog.dimension_partition dp ON (dp.dimension_id = d.id)
ORDER BY dimension_id, range_start;
GRANT SELECT ON hypertable_partitions TO :ROLE_1;
-- Import testsupport.sql file to data nodes
\unset ECHO
GRANT CREATE ON SCHEMA public TO :ROLE_1;
SET ROLE :ROLE_1;
--Ensure INSERTs use DataNodeDispatch. DataNodeCopy is tested later
SET timescaledb.enable_distributed_insert_with_copy=false;
-- Verify lack of tables
SELECT node_name FROM timescaledb_information.data_nodes ORDER BY node_name;
      node_name       
----------------------
 db_dist_hypertable_1
 db_dist_hypertable_2
 db_dist_hypertable_3
(3 rows)

\set ON_ERROR_STOP 0
-- Test that one cannot directly create TimescaleDB foreign tables
CREATE FOREIGN TABLE foreign_table (time timestamptz, device int, temp float) SERVER :DATA_NODE_1;
ERROR:  operation not supported
\set ON_ERROR_STOP 1
-- Create distributed hypertables. Add a trigger and primary key
-- constraint to test how those work
CREATE TABLE disttable(time timestamptz, device int CHECK (device > 0), color int, temp float, PRIMARY KEY (time,device));
SELECT * FROM create_distributed_hypertable('disttable', 'time', 'device', 1);
WARNING:  insufficient number of partitions for dimension "device"
 hypertable_id | schema_name | table_name | created 
---------------+-------------+------------+---------
             1 | public      | disttable  | t
(1 row)

-- Increase the number of partitions. Expect warning since still too
-- low. Dimension partitions should be updated to reflect new
-- partitioning.
SELECT * FROM hypertable_partitions WHERE table_name = 'disttable';
 table_name | dimension_id |     range_start      |       data_nodes       
------------+--------------+----------------------+------------------------
 disttable  |            2 | -9223372036854775808 | {db_dist_hypertable_1}
(1 row)

SELECT * FROM set_number_partitions('disttable', 2);
WARNING:  insufficient number of partitions for dimension "device"
 set_number_partitions 
-----------------------
 
(1 row)

SELECT * FROM hypertable_partitions WHERE table_name = 'disttable';
 table_name | dimension_id |     range_start      |       data_nodes       
------------+--------------+----------------------+------------------------
 disttable  |            2 | -9223372036854775808 | {db_dist_hypertable_1}
 disttable  |            2 |           1073741823 | {db_dist_hypertable_2}
(2 rows)

-- Set number of partitions equal to the number of servers should not
-- raise a warning.
SELECT * FROM hypertable_partitions WHERE table_name = 'disttable';
 table_name | dimension_id |     range_start      |       data_nodes       
------------+--------------+----------------------+------------------------
 disttable  |            2 | -9223372036854775808 | {db_dist_hypertable_1}
 disttable  |            2 |           1073741823 | {db_dist_hypertable_2}
(2 rows)

SELECT * FROM set_number_partitions('disttable', 3, 'device');
 set_number_partitions 
-----------------------
 
(1 row)

SELECT * FROM hypertable_partitions WHERE table_name = 'disttable';
 table_name | dimension_id |     range_start      |       data_nodes       
------------+--------------+----------------------+------------------------
 disttable  |            2 | -9223372036854775808 | {db_dist_hypertable_1}
 disttable  |            2 |            715827882 | {db_dist_hypertable_2}
 disttable  |            2 |           1431655764 | {db_dist_hypertable_3}
(3 rows)

-- Show the number of slices
SELECT h.table_name, d.column_name, d.num_slices
FROM _timescaledb_catalog.hypertable h, _timescaledb_catalog.dimension d
WHERE h.id = d.hypertable_id
AND h.table_name = 'disttable';
 table_name | column_name | num_slices 
------------+-------------+------------
 disttable  | device      |          3
 disttable  | time        |           
(2 rows)

-- This table tests both 1-dimensional tables and under-replication
-- (replication_factor > num_data_nodes).
CREATE TABLE underreplicated(time timestamptz, device int, temp float);
\set ON_ERROR_STOP 0
-- can't create an under-replicated hypertable
SELECT * FROM create_hypertable('underreplicated', 'time', replication_factor => 4);
ERROR:  replication factor too large for hypertable "underreplicated"
\set ON_ERROR_STOP 1
RESET ROLE;
SELECT node_name, database, node_created, database_created, extension_created
FROM add_data_node(:'DATA_NODE_4', host => 'localhost', database => :'DATA_NODE_4');
      node_name       |       database       | node_created | database_created | extension_created 
----------------------+----------------------+--------------+------------------+-------------------
 db_dist_hypertable_4 | db_dist_hypertable_4 | t            | t                | t
(1 row)

GRANT USAGE ON FOREIGN SERVER :DATA_NODE_4 TO PUBLIC;
GRANT CREATE ON SCHEMA public TO :ROLE_1;
SET ROLE :ROLE_1;
SELECT * FROM create_hypertable('underreplicated', 'time', replication_factor => 4);
NOTICE:  adding not-null constraint to column "time"
 hypertable_id | schema_name |   table_name    | created 
---------------+-------------+-----------------+---------
             2 | public      | underreplicated | t
(1 row)

-- test that attaching a data node to an existing hypertable with
-- repartition=>false does not change the number of partitions when
-- number of partitions is greater than number of data nodes.
SELECT * FROM set_number_partitions('disttable', 8, 'device');
 set_number_partitions 
-----------------------
 
(1 row)

SELECT * FROM hypertable_partitions WHERE table_name = 'disttable';
 table_name | dimension_id |     range_start      |       data_nodes       
------------+--------------+----------------------+------------------------
 disttable  |            2 | -9223372036854775808 | {db_dist_hypertable_1}
 disttable  |            2 |            268435455 | {db_dist_hypertable_2}
 disttable  |            2 |            536870910 | {db_dist_hypertable_3}
 disttable  |            2 |            805306365 | {db_dist_hypertable_1}
 disttable  |            2 |           1073741820 | {db_dist_hypertable_2}
 disttable  |            2 |           1342177275 | {db_dist_hypertable_3}
 disttable  |            2 |           1610612730 | {db_dist_hypertable_1}
 disttable  |            2 |           1879048185 | {db_dist_hypertable_2}
(8 rows)

SELECT attach_data_node(:'DATA_NODE_4', 'disttable', repartition => false);
      attach_data_node      
----------------------------
 (1,2,db_dist_hypertable_4)
(1 row)

SELECT * FROM hypertable_partitions WHERE table_name = 'disttable';
 table_name | dimension_id |     range_start      |       data_nodes       
------------+--------------+----------------------+------------------------
 disttable  |            2 | -9223372036854775808 | {db_dist_hypertable_1}
 disttable  |            2 |            268435455 | {db_dist_hypertable_2}
 disttable  |            2 |            536870910 | {db_dist_hypertable_3}
 disttable  |            2 |            805306365 | {db_dist_hypertable_4}
 disttable  |            2 |           1073741820 | {db_dist_hypertable_1}
 disttable  |            2 |           1342177275 | {db_dist_hypertable_2}
 disttable  |            2 |           1610612730 | {db_dist_hypertable_3}
 disttable  |            2 |           1879048185 | {db_dist_hypertable_4}
(8 rows)

--create new session to clear out connections
\c :TEST_DBNAME :ROLE_CLUSTER_SUPERUSER;
SELECT * FROM delete_data_node(:'DATA_NODE_4', force => true, drop_database => true, repartition => false);
WARNING:  insufficient number of data nodes for distributed hypertable "underreplicated"
 delete_data_node 
------------------
 t
(1 row)

SET ROLE :ROLE_1;
-- Deleting a data node should also not change the number of
-- partitions with repartition=>false
SELECT * FROM hypertable_partitions WHERE table_name = 'disttable';
 table_name | dimension_id |     range_start      |       data_nodes       
------------+--------------+----------------------+------------------------
 disttable  |            2 | -9223372036854775808 | {db_dist_hypertable_1}
 disttable  |            2 |            268435455 | {db_dist_hypertable_2}
 disttable  |            2 |            536870910 | {db_dist_hypertable_3}
 disttable  |            2 |            805306365 | {db_dist_hypertable_1}
 disttable  |            2 |           1073741820 | {db_dist_hypertable_2}
 disttable  |            2 |           1342177275 | {db_dist_hypertable_3}
 disttable  |            2 |           1610612730 | {db_dist_hypertable_1}
 disttable  |            2 |           1879048185 | {db_dist_hypertable_2}
(8 rows)

CREATE OR REPLACE FUNCTION test_trigger()
    RETURNS TRIGGER LANGUAGE PLPGSQL AS
$BODY$
DECLARE
    cnt INTEGER;
BEGIN
    SELECT count(*) INTO cnt FROM public.disttable;
    RAISE WARNING 'FIRING trigger when: % level: % op: % cnt: % trigger_name %',
        tg_when, tg_level, tg_op, cnt, tg_name;

    IF TG_OP = 'DELETE' THEN
        RETURN OLD;
    END IF;
    RETURN NEW;
END
$BODY$;
-- Create the trigger function on the data nodes:
CALL distributed_exec($$
CREATE OR REPLACE FUNCTION test_trigger()
    RETURNS TRIGGER LANGUAGE PLPGSQL AS
$BODY$
DECLARE
    cnt INTEGER;
BEGIN
    SELECT count(*) INTO cnt FROM public.disttable;
    RAISE WARNING 'FIRING trigger when: % level: % op: % cnt: % trigger_name %',
        tg_when, tg_level, tg_op, cnt, tg_name;

    IF TG_OP = 'DELETE' THEN
        RETURN OLD;
    END IF;
    RETURN NEW;
END
$BODY$;
$$);
CREATE TRIGGER _0_test_trigger_insert
    BEFORE INSERT ON disttable
    FOR EACH ROW EXECUTE FUNCTION test_trigger();
SELECT * FROM _timescaledb_catalog.hypertable_data_node ORDER BY 1,2,3;
 hypertable_id | node_hypertable_id |      node_name       | block_chunks 
---------------+--------------------+----------------------+--------------
             1 |                  1 | db_dist_hypertable_1 | f
             1 |                  1 | db_dist_hypertable_2 | f
             1 |                  1 | db_dist_hypertable_3 | f
             2 |                  2 | db_dist_hypertable_1 | f
             2 |                  2 | db_dist_hypertable_2 | f
             2 |                  2 | db_dist_hypertable_3 | f
(6 rows)

SELECT * FROM _timescaledb_catalog.chunk_data_node ORDER BY 1,2,3;
 chunk_id | node_chunk_id | node_name 
----------+---------------+-----------
(0 rows)

-- The constraints, indexes, and triggers on the hypertable
SELECT * FROM test.show_constraints('disttable');
       Constraint       | Type |    Columns    |     Index      |     Expr     | Deferrable | Deferred | Validated 
------------------------+------+---------------+----------------+--------------+------------+----------+-----------
 disttable_device_check | c    | {device}      | -              | (device > 0) | f          | f        | t
 disttable_pkey         | p    | {time,device} | disttable_pkey |              | f          | f        | t
(2 rows)

SELECT * FROM test.show_indexes('disttable');
           Index           |    Columns    | Expr | Unique | Primary | Exclusion | Tablespace 
---------------------------+---------------+------+--------+---------+-----------+------------
 disttable_device_time_idx | {device,time} |      | f      | f       | f         | 
 disttable_pkey            | {time,device} |      | t      | t       | f         | 
 disttable_time_idx        | {time}        |      | f      | f       | f         | 
(3 rows)

SELECT * FROM test.show_triggers('disttable');
        Trigger         | Type |               Function               
------------------------+------+--------------------------------------
 _0_test_trigger_insert |    7 | test_trigger
 ts_insert_blocker      |    7 | _timescaledb_internal.insert_blocker
(2 rows)

-- Drop a column. This will make the attribute numbers of the
-- hypertable's root relation differ from newly created chunks. It is
-- a way to test that we properly handle attributed conversion between
-- the root table and chunks
ALTER TABLE disttable DROP COLUMN color;
-- EXPLAIN some inserts to see what plans and explain output for
-- remote inserts look like
EXPLAIN (COSTS FALSE)
INSERT INTO disttable VALUES
       ('2017-01-01 06:01', 1, 1.1);
                  QUERY PLAN                   
-----------------------------------------------
 Custom Scan (HypertableModify)
 Insert on distributed hypertable disttable
   ->  Insert on disttable
         ->  Custom Scan (DataNodeCopy)
               ->  Custom Scan (ChunkDispatch)
                     ->  Result
(6 rows)

EXPLAIN (VERBOSE, COSTS FALSE)
INSERT INTO disttable VALUES
       ('2017-01-01 06:01', 1, 1.1);
                                                              QUERY PLAN                                                               
---------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (HypertableModify)
 Insert on distributed hypertable public.disttable
   Data nodes: db_dist_hypertable_1, db_dist_hypertable_2, db_dist_hypertable_3
   ->  Insert on public.disttable
         ->  Custom Scan (DataNodeCopy)
               Output: 'Sun Jan 01 06:01:00 2017 PST'::timestamp with time zone, 1, NULL::integer, '1.1'::double precision
               Remote SQL: COPY public.disttable ("time", device, temp) FROM STDIN WITH (FORMAT binary)
               ->  Custom Scan (ChunkDispatch)
                     Output: 'Sun Jan 01 06:01:00 2017 PST'::timestamp with time zone, 1, NULL::integer, '1.1'::double precision
                     ->  Result
                           Output: 'Sun Jan 01 06:01:00 2017 PST'::timestamp with time zone, 1, NULL::integer, '1.1'::double precision
(11 rows)

-- Create some chunks through insertion
INSERT INTO disttable VALUES
       ('2017-01-01 06:01', 1, 1.1),
       ('2017-01-01 09:11', 3, 2.1),
       ('2017-01-01 09:21', 3, 2.2),
       ('2017-01-01 08:11', 3, 2.3),
       ('2017-01-01 08:01', 1, 1.2),
       ('2017-01-02 08:01', 2, 1.3),
       ('2017-01-02 09:01', 2, 1.4),
       ('2017-01-02 08:21', 2, 1.5),
       ('2018-07-02 08:01', 87, 1.6),
       ('2018-07-02 09:01', 87, 1.4),
       ('2018-07-02 09:21', 87, 1.8),
       ('2018-07-01 06:01', 13, 1.4),
       ('2018-07-01 06:21', 13, 1.5),
       ('2018-07-01 07:01', 13, 1.4),
       ('2018-07-01 09:11', 90, 2.7),
       ('2018-07-01 08:01', 29, 1.5),
       ('2018-07-01 09:21', 90, 2.8),
       ('2018-07-01 08:21', 29, 1.2);
-- EXPLAIN some updates/deletes to see what plans and explain output for
-- remote operations look like
EXPLAIN (VERBOSE, COSTS FALSE)
UPDATE disttable SET temp = 3.7 WHERE device = 1;
                                                               QUERY PLAN                                                                
-----------------------------------------------------------------------------------------------------------------------------------------
 Update on public.disttable
   Update on public.disttable disttable_1
   Foreign Update on _timescaledb_internal._dist_hyper_1_1_chunk disttable_2
     Remote SQL: UPDATE _timescaledb_internal._dist_hyper_1_1_chunk SET temp = $2 WHERE ctid = $1
   ->  Result
         Output: '3.7'::double precision, disttable.tableoid, disttable.ctid, (NULL::record)
         ->  Append
               ->  Seq Scan on public.disttable disttable_1
                     Output: disttable_1.tableoid, disttable_1.ctid, NULL::record
                     Filter: (disttable_1.device = 1)
               ->  Foreign Scan on _timescaledb_internal._dist_hyper_1_1_chunk disttable_2
                     Output: disttable_2.tableoid, disttable_2.ctid, disttable_2.*
                     Data node: db_dist_hypertable_1
                     Remote SQL: SELECT "time", device, temp, ctid FROM _timescaledb_internal._dist_hyper_1_1_chunk WHERE ((device = 1))
(14 rows)

EXPLAIN (VERBOSE, COSTS FALSE)
DELETE FROM disttable WHERE device = 1;
                                                 QUERY PLAN                                                  
-------------------------------------------------------------------------------------------------------------
 Delete on public.disttable
   Delete on public.disttable disttable_1
   Foreign Delete on _timescaledb_internal._dist_hyper_1_1_chunk disttable_2
     Remote SQL: DELETE FROM _timescaledb_internal._dist_hyper_1_1_chunk WHERE ctid = $1
   ->  Append
         ->  Seq Scan on public.disttable disttable_1
               Output: disttable_1.tableoid, disttable_1.ctid
               Filter: (disttable_1.device = 1)
         ->  Foreign Scan on _timescaledb_internal._dist_hyper_1_1_chunk disttable_2
               Output: disttable_2.tableoid, disttable_2.ctid
               Data node: db_dist_hypertable_1
               Remote SQL: SELECT ctid FROM _timescaledb_internal._dist_hyper_1_1_chunk WHERE ((device = 1))
(12 rows)

-- Test distributed ANALYZE.
--
-- First show no statistics
-- reltuples is initially -1 before any VACUUM/ANALYZE has been run on PG14
SELECT relname, relkind, CASE WHEN reltuples > 0 THEN reltuples ELSE 0 END AS reltuples, relpages
FROM pg_class
WHERE oid = 'disttable'::regclass;
  relname  | relkind | reltuples | relpages 
-----------+---------+-----------+----------
 disttable | r       |         0 |        0
(1 row)

SELECT relname, relkind, CASE WHEN reltuples > 0 THEN reltuples ELSE 0 END AS reltuples, relpages
FROM pg_class cl, (SELECT show_chunks AS chunk FROM show_chunks('disttable')) ch
WHERE cl.oid = ch.chunk::regclass;
        relname        | relkind | reltuples | relpages 
-----------------------+---------+-----------+----------
 _dist_hyper_1_1_chunk | f       |         0 |        0
 _dist_hyper_1_2_chunk | f       |         0 |        0
 _dist_hyper_1_3_chunk | f       |         0 |        0
 _dist_hyper_1_4_chunk | f       |         0 |        0
 _dist_hyper_1_5_chunk | f       |         0 |        0
 _dist_hyper_1_6_chunk | f       |         0 |        0
 _dist_hyper_1_7_chunk | f       |         0 |        0
(7 rows)

ANALYZE disttable;
-- Show updated statistics
SELECT relname, relkind, CASE WHEN reltuples > 0 THEN reltuples ELSE 0 END AS reltuples, relpages
FROM pg_class
WHERE oid = 'disttable'::regclass;
  relname  | relkind | reltuples | relpages 
-----------+---------+-----------+----------
 disttable | r       |         0 |        0
(1 row)

SELECT relname, relkind, reltuples, relpages
FROM pg_class cl, (SELECT show_chunks AS chunk FROM show_chunks('disttable')) ch
WHERE cl.oid = ch.chunk::regclass;
        relname        | relkind | reltuples | relpages 
-----------------------+---------+-----------+----------
 _dist_hyper_1_1_chunk | f       |         2 |        1
 _dist_hyper_1_2_chunk | f       |         3 |        1
 _dist_hyper_1_3_chunk | f       |         3 |        1
 _dist_hyper_1_4_chunk | f       |         3 |        1
 _dist_hyper_1_5_chunk | f       |         3 |        1
 _dist_hyper_1_6_chunk | f       |         2 |        1
 _dist_hyper_1_7_chunk | f       |         2 |        1
(7 rows)

-- Test distributed VACUUM.
--
VACUUM (FULL, ANALYZE) disttable;
VACUUM FULL disttable;
VACUUM disttable;
\set ON_ERROR_STOP 0
-- VACUUM VERBOSE is not supported at the moment
VACUUM VERBOSE disttable;
ERROR:  operation not supported on distributed hypertable
\set ON_ERROR_STOP 1
-- Test prepared statement
PREPARE dist_insert (timestamptz, int, float) AS
INSERT INTO disttable VALUES ($1, $2, $3);
EXECUTE dist_insert ('2017-01-01 06:05', 1, 1.4);
-- Show chunks created
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable');
 chunk_id | hypertable_id |      schema_name      |      table_name       | relkind |                                           slices                                            
----------+---------------+-----------------------+-----------------------+---------+---------------------------------------------------------------------------------------------
        1 |             1 | _timescaledb_internal | _dist_hyper_1_1_chunk | f       | {"time": [1482969600000000, 1483574400000000], "device": [-9223372036854775808, 268435455]}
        2 |             1 | _timescaledb_internal | _dist_hyper_1_2_chunk | f       | {"time": [1482969600000000, 1483574400000000], "device": [1879048185, 9223372036854775807]}
        3 |             1 | _timescaledb_internal | _dist_hyper_1_3_chunk | f       | {"time": [1482969600000000, 1483574400000000], "device": [1073741820, 1342177275]}
        4 |             1 | _timescaledb_internal | _dist_hyper_1_4_chunk | f       | {"time": [1530144000000000, 1530748800000000], "device": [268435455, 536870910]}
        5 |             1 | _timescaledb_internal | _dist_hyper_1_5_chunk | f       | {"time": [1530144000000000, 1530748800000000], "device": [805306365, 1073741820]}
        6 |             1 | _timescaledb_internal | _dist_hyper_1_6_chunk | f       | {"time": [1530144000000000, 1530748800000000], "device": [1610612730, 1879048185]}
        7 |             1 | _timescaledb_internal | _dist_hyper_1_7_chunk | f       | {"time": [1530144000000000, 1530748800000000], "device": [1879048185, 9223372036854775807]}
(7 rows)

-- Show that there are assigned node_chunk_id:s in chunk data node mappings
SELECT * FROM _timescaledb_catalog.chunk_data_node ORDER BY 1,2,3;
 chunk_id | node_chunk_id |      node_name       
----------+---------------+----------------------
        1 |             1 | db_dist_hypertable_1
        2 |             1 | db_dist_hypertable_2
        3 |             2 | db_dist_hypertable_2
        4 |             3 | db_dist_hypertable_2
        5 |             2 | db_dist_hypertable_1
        6 |             3 | db_dist_hypertable_1
        7 |             4 | db_dist_hypertable_2
(7 rows)

SELECT * FROM hypertable_partitions;
 table_name | dimension_id |     range_start      |       data_nodes       
------------+--------------+----------------------+------------------------
 disttable  |            2 | -9223372036854775808 | {db_dist_hypertable_1}
 disttable  |            2 |            268435455 | {db_dist_hypertable_2}
 disttable  |            2 |            536870910 | {db_dist_hypertable_3}
 disttable  |            2 |            805306365 | {db_dist_hypertable_1}
 disttable  |            2 |           1073741820 | {db_dist_hypertable_2}
 disttable  |            2 |           1342177275 | {db_dist_hypertable_3}
 disttable  |            2 |           1610612730 | {db_dist_hypertable_1}
 disttable  |            2 |           1879048185 | {db_dist_hypertable_2}
(8 rows)

-- Show that chunks are created on data nodes and that each data node
-- has their own unique slice in the space (device) dimension.
SELECT * FROM test.remote_exec(ARRAY[:'DATA_NODE_1', :'DATA_NODE_2', :'DATA_NODE_3'], $$
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable');
$$);
NOTICE:  [db_dist_hypertable_1]: 
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable')
NOTICE:  [db_dist_hypertable_1]:
chunk_id|hypertable_id|schema_name          |table_name           |relkind|slices                                                                                     
--------+-------------+---------------------+---------------------+-------+-------------------------------------------------------------------------------------------
       1|            1|_timescaledb_internal|_dist_hyper_1_1_chunk|r      |{"time": [1482969600000000, 1483574400000000], "device": [-9223372036854775808, 268435455]}
       2|            1|_timescaledb_internal|_dist_hyper_1_5_chunk|r      |{"time": [1530144000000000, 1530748800000000], "device": [805306365, 1073741820]}          
       3|            1|_timescaledb_internal|_dist_hyper_1_6_chunk|r      |{"time": [1530144000000000, 1530748800000000], "device": [1610612730, 1879048185]}         
(3 rows)


NOTICE:  [db_dist_hypertable_2]: 
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable')
NOTICE:  [db_dist_hypertable_2]:
chunk_id|hypertable_id|schema_name          |table_name           |relkind|slices                                                                                     
--------+-------------+---------------------+---------------------+-------+-------------------------------------------------------------------------------------------
       1|            1|_timescaledb_internal|_dist_hyper_1_2_chunk|r      |{"time": [1482969600000000, 1483574400000000], "device": [1879048185, 9223372036854775807]}
       2|            1|_timescaledb_internal|_dist_hyper_1_3_chunk|r      |{"time": [1482969600000000, 1483574400000000], "device": [1073741820, 1342177275]}         
       3|            1|_timescaledb_internal|_dist_hyper_1_4_chunk|r      |{"time": [1530144000000000, 1530748800000000], "device": [268435455, 536870910]}           
       4|            1|_timescaledb_internal|_dist_hyper_1_7_chunk|r      |{"time": [1530144000000000, 1530748800000000], "device": [1879048185, 9223372036854775807]}
(4 rows)


NOTICE:  [db_dist_hypertable_3]: 
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable')
NOTICE:  [db_dist_hypertable_3]:
chunk_id|hypertable_id|schema_name|table_name|relkind|slices
--------+-------------+-----------+----------+-------+------
(0 rows)


 remote_exec 
-------------
 
(1 row)

SELECT * FROM test.remote_exec(ARRAY[:'DATA_NODE_1', :'DATA_NODE_2', :'DATA_NODE_3'], $$
SELECT * FROM disttable;
$$);
NOTICE:  [db_dist_hypertable_1]: 
SELECT * FROM disttable
NOTICE:  [db_dist_hypertable_1]:
time                        |device|temp
----------------------------+------+----
Sun Jan 01 06:01:00 2017 PST|     1| 1.1
Sun Jan 01 08:01:00 2017 PST|     1| 1.2
Sun Jan 01 06:05:00 2017 PST|     1| 1.4
Sun Jul 01 06:01:00 2018 PDT|    13| 1.4
Sun Jul 01 06:21:00 2018 PDT|    13| 1.5
Sun Jul 01 07:01:00 2018 PDT|    13| 1.4
Sun Jul 01 09:11:00 2018 PDT|    90| 2.7
Sun Jul 01 09:21:00 2018 PDT|    90| 2.8
(8 rows)


NOTICE:  [db_dist_hypertable_2]: 
SELECT * FROM disttable
NOTICE:  [db_dist_hypertable_2]:
time                        |device|temp
----------------------------+------+----
Sun Jan 01 09:11:00 2017 PST|     3| 2.1
Sun Jan 01 09:21:00 2017 PST|     3| 2.2
Sun Jan 01 08:11:00 2017 PST|     3| 2.3
Mon Jan 02 08:01:00 2017 PST|     2| 1.3
Mon Jan 02 09:01:00 2017 PST|     2| 1.4
Mon Jan 02 08:21:00 2017 PST|     2| 1.5
Mon Jul 02 08:01:00 2018 PDT|    87| 1.6
Mon Jul 02 09:01:00 2018 PDT|    87| 1.4
Mon Jul 02 09:21:00 2018 PDT|    87| 1.8
Sun Jul 01 08:01:00 2018 PDT|    29| 1.5
Sun Jul 01 08:21:00 2018 PDT|    29| 1.2
(11 rows)


NOTICE:  [db_dist_hypertable_3]: 
SELECT * FROM disttable
NOTICE:  [db_dist_hypertable_3]:
time|device|temp
----+------+----
(0 rows)


 remote_exec 
-------------
 
(1 row)

SELECT node_name FROM timescaledb_information.data_nodes ORDER BY node_name;
      node_name       
----------------------
 db_dist_hypertable_1
 db_dist_hypertable_2
 db_dist_hypertable_3
(3 rows)

SELECT * FROM hypertable_detailed_size('disttable') ORDER BY node_name;
 table_bytes | index_bytes | toast_bytes | total_bytes |      node_name       
-------------+-------------+-------------+-------------+----------------------
      122880 |      172032 |           0 |      294912 | db_dist_hypertable_1
      163840 |      221184 |           0 |      385024 | db_dist_hypertable_2
           0 |       24576 |           0 |       24576 | db_dist_hypertable_3
           0 |       24576 |           0 |       24576 | 
(4 rows)

-- Show what some queries would look like on the frontend
EXPLAIN (VERBOSE, COSTS FALSE)
SELECT * FROM disttable;
                                                                        QUERY PLAN                                                                        
----------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: disttable."time", disttable.device, disttable.temp
   ->  Append
         ->  Custom Scan (DataNodeScan) on public.disttable disttable_1
               Output: disttable_1."time", disttable_1.device, disttable_1.temp
               Data node: db_dist_hypertable_1
               Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_6_chunk
               Remote SQL: SELECT "time", device, temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2, 3])
         ->  Custom Scan (DataNodeScan) on public.disttable disttable_2
               Output: disttable_2."time", disttable_2.device, disttable_2.temp
               Data node: db_dist_hypertable_2
               Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_3_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_7_chunk
               Remote SQL: SELECT "time", device, temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2, 3, 4])
(13 rows)

SELECT * FROM disttable;
             time             | device | temp 
------------------------------+--------+------
 Sun Jan 01 06:01:00 2017 PST |      1 |  1.1
 Sun Jan 01 08:01:00 2017 PST |      1 |  1.2
 Sun Jan 01 06:05:00 2017 PST |      1 |  1.4
 Sun Jul 01 06:01:00 2018 PDT |     13 |  1.4
 Sun Jul 01 06:21:00 2018 PDT |     13 |  1.5
 Sun Jul 01 07:01:00 2018 PDT |     13 |  1.4
 Sun Jul 01 09:11:00 2018 PDT |     90 |  2.7
 Sun Jul 01 09:21:00 2018 PDT |     90 |  2.8
 Sun Jan 01 09:11:00 2017 PST |      3 |  2.1
 Sun Jan 01 09:21:00 2017 PST |      3 |  2.2
 Sun Jan 01 08:11:00 2017 PST |      3 |  2.3
 Mon Jan 02 08:01:00 2017 PST |      2 |  1.3
 Mon Jan 02 09:01:00 2017 PST |      2 |  1.4
 Mon Jan 02 08:21:00 2017 PST |      2 |  1.5
 Mon Jul 02 08:01:00 2018 PDT |     87 |  1.6
 Mon Jul 02 09:01:00 2018 PDT |     87 |  1.4
 Mon Jul 02 09:21:00 2018 PDT |     87 |  1.8
 Sun Jul 01 08:01:00 2018 PDT |     29 |  1.5
 Sun Jul 01 08:21:00 2018 PDT |     29 |  1.2
(19 rows)

EXPLAIN (VERBOSE, COSTS FALSE)
SELECT time_bucket('3 hours', time) AS time, device, avg(temp) AS avg_temp
FROM disttable GROUP BY 1, 2
ORDER BY 1;
                                                                                                                              QUERY PLAN                                                                                                                              
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 GroupAggregate
   Output: (time_bucket('@ 3 hours'::interval, disttable."time")), disttable.device, avg(disttable.temp)
   Group Key: (time_bucket('@ 3 hours'::interval, disttable."time")), disttable.device
   ->  Custom Scan (AsyncAppend)
         Output: (time_bucket('@ 3 hours'::interval, disttable."time")), disttable.device, disttable.temp
         ->  Merge Append
               Sort Key: (time_bucket('@ 3 hours'::interval, disttable_1."time")), disttable_1.device
               ->  Result
                     Output: time_bucket('@ 3 hours'::interval, disttable_1."time"), disttable_1.device, disttable_1.temp
                     ->  Custom Scan (DataNodeScan) on public.disttable disttable_1
                           Output: disttable_1."time", disttable_1.device, disttable_1.temp
                           Data node: db_dist_hypertable_1
                           Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_6_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2, 3]) ORDER BY public.time_bucket('03:00:00'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
               ->  Result
                     Output: time_bucket('@ 3 hours'::interval, disttable_2."time"), disttable_2.device, disttable_2.temp
                     ->  Custom Scan (DataNodeScan) on public.disttable disttable_2
                           Output: disttable_2."time", disttable_2.device, disttable_2.temp
                           Data node: db_dist_hypertable_2
                           Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_3_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_7_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2, 3, 4]) ORDER BY public.time_bucket('03:00:00'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
(21 rows)

-- Execute some queries on the frontend and return the results
SELECT * FROM disttable;
             time             | device | temp 
------------------------------+--------+------
 Sun Jan 01 06:01:00 2017 PST |      1 |  1.1
 Sun Jan 01 08:01:00 2017 PST |      1 |  1.2
 Sun Jan 01 06:05:00 2017 PST |      1 |  1.4
 Sun Jul 01 06:01:00 2018 PDT |     13 |  1.4
 Sun Jul 01 06:21:00 2018 PDT |     13 |  1.5
 Sun Jul 01 07:01:00 2018 PDT |     13 |  1.4
 Sun Jul 01 09:11:00 2018 PDT |     90 |  2.7
 Sun Jul 01 09:21:00 2018 PDT |     90 |  2.8
 Sun Jan 01 09:11:00 2017 PST |      3 |  2.1
 Sun Jan 01 09:21:00 2017 PST |      3 |  2.2
 Sun Jan 01 08:11:00 2017 PST |      3 |  2.3
 Mon Jan 02 08:01:00 2017 PST |      2 |  1.3
 Mon Jan 02 09:01:00 2017 PST |      2 |  1.4
 Mon Jan 02 08:21:00 2017 PST |      2 |  1.5
 Mon Jul 02 08:01:00 2018 PDT |     87 |  1.6
 Mon Jul 02 09:01:00 2018 PDT |     87 |  1.4
 Mon Jul 02 09:21:00 2018 PDT |     87 |  1.8
 Sun Jul 01 08:01:00 2018 PDT |     29 |  1.5
 Sun Jul 01 08:21:00 2018 PDT |     29 |  1.2
(19 rows)

SELECT time_bucket('3 hours', time) AS time, device, avg(temp) AS avg_temp
FROM disttable
GROUP BY 1, 2
ORDER BY 1;
             time             | device |     avg_temp     
------------------------------+--------+------------------
 Sun Jan 01 04:00:00 2017 PST |      1 |             1.25
 Sun Jan 01 07:00:00 2017 PST |      1 |              1.2
 Sun Jan 01 07:00:00 2017 PST |      3 |              2.2
 Mon Jan 02 07:00:00 2017 PST |      2 |              1.4
 Sun Jul 01 05:00:00 2018 PDT |     13 | 1.43333333333333
 Sun Jul 01 08:00:00 2018 PDT |     29 |             1.35
 Sun Jul 01 08:00:00 2018 PDT |     90 |             2.75
 Mon Jul 02 08:00:00 2018 PDT |     87 |              1.6
(8 rows)

SELECT time_bucket('3 hours', time) AS time, device, avg(temp) AS avg_temp
FROM disttable GROUP BY 1, 2
HAVING avg(temp) > 1.2
ORDER BY 1;
             time             | device |     avg_temp     
------------------------------+--------+------------------
 Sun Jan 01 04:00:00 2017 PST |      1 |             1.25
 Sun Jan 01 07:00:00 2017 PST |      3 |              2.2
 Mon Jan 02 07:00:00 2017 PST |      2 |              1.4
 Sun Jul 01 05:00:00 2018 PDT |     13 | 1.43333333333333
 Sun Jul 01 08:00:00 2018 PDT |     29 |             1.35
 Sun Jul 01 08:00:00 2018 PDT |     90 |             2.75
 Mon Jul 02 08:00:00 2018 PDT |     87 |              1.6
(7 rows)

SELECT time_bucket('3 hours', time) AS time, device, avg(temp) AS avg_temp
FROM disttable
WHERE temp > 2
GROUP BY 1, 2
HAVING avg(temp) > 1.2
ORDER BY 1;
             time             | device | avg_temp 
------------------------------+--------+----------
 Sun Jan 01 07:00:00 2017 PST |      3 |      2.2
 Sun Jul 01 08:00:00 2018 PDT |     90 |     2.75
(2 rows)

-- Test AsyncAppend when using min/max aggregates
EXPLAIN (VERBOSE, COSTS FALSE)
SELECT max(temp)
FROM disttable;
                                                                                                       QUERY PLAN                                                                                                       
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Result
   Output: $0
   InitPlan 1 (returns $0)
     ->  Limit
           Output: disttable.temp
           ->  Custom Scan (AsyncAppend)
                 Output: disttable.temp
                 ->  Merge Append
                       Sort Key: disttable_1.temp DESC
                       ->  Custom Scan (DataNodeScan) on public.disttable disttable_1
                             Output: disttable_1.temp
                             Data node: db_dist_hypertable_1
                             Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_6_chunk
                             Remote SQL: SELECT temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2, 3]) AND ((temp IS NOT NULL)) ORDER BY temp DESC NULLS FIRST LIMIT 1
                       ->  Custom Scan (DataNodeScan) on public.disttable disttable_2
                             Output: disttable_2.temp
                             Data node: db_dist_hypertable_2
                             Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_3_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_7_chunk
                             Remote SQL: SELECT temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2, 3, 4]) AND ((temp IS NOT NULL)) ORDER BY temp DESC NULLS FIRST LIMIT 1
(19 rows)

SELECT max(temp)
FROM disttable;
 max 
-----
 2.8
(1 row)

-- Test turning off async append
SET timescaledb.enable_async_append = OFF;
EXPLAIN (VERBOSE, COSTS FALSE)
SELECT max(temp)
FROM disttable;
                                                                                                    QUERY PLAN                                                                                                    
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Result
   Output: $0
   InitPlan 1 (returns $0)
     ->  Limit
           Output: disttable_1.temp
           ->  Merge Append
                 Sort Key: disttable_1.temp DESC
                 ->  Custom Scan (DataNodeScan) on public.disttable disttable_1
                       Output: disttable_1.temp
                       Data node: db_dist_hypertable_1
                       Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_6_chunk
                       Remote SQL: SELECT temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2, 3]) AND ((temp IS NOT NULL)) ORDER BY temp DESC NULLS FIRST LIMIT 1
                 ->  Custom Scan (DataNodeScan) on public.disttable disttable_2
                       Output: disttable_2.temp
                       Data node: db_dist_hypertable_2
                       Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_3_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_7_chunk
                       Remote SQL: SELECT temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2, 3, 4]) AND ((temp IS NOT NULL)) ORDER BY temp DESC NULLS FIRST LIMIT 1
(17 rows)

SET timescaledb.enable_async_append = ON;
EXPLAIN (VERBOSE, COSTS FALSE)
SELECT min(temp), max(temp)
FROM disttable;
                                                                   QUERY PLAN                                                                   
------------------------------------------------------------------------------------------------------------------------------------------------
 Aggregate
   Output: min(disttable.temp), max(disttable.temp)
   ->  Custom Scan (AsyncAppend)
         Output: disttable.temp
         ->  Append
               ->  Custom Scan (DataNodeScan) on public.disttable disttable_1
                     Output: disttable_1.temp
                     Data node: db_dist_hypertable_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_6_chunk
                     Remote SQL: SELECT temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2, 3])
               ->  Custom Scan (DataNodeScan) on public.disttable disttable_2
                     Output: disttable_2.temp
                     Data node: db_dist_hypertable_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_3_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_7_chunk
                     Remote SQL: SELECT temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2, 3, 4])
(15 rows)

SELECT min(temp), max(temp)
FROM disttable;
 min | max 
-----+-----
 1.1 | 2.8
(1 row)

-- Test AsyncAppend when using window functions
EXPLAIN (VERBOSE, COSTS FALSE)
SELECT device, temp, avg(temp) OVER (PARTITION BY device)
FROM disttable
ORDER BY device, temp;
                                                                                         QUERY PLAN                                                                                          
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Incremental Sort
   Output: disttable.device, disttable.temp, (avg(disttable.temp) OVER (?))
   Sort Key: disttable.device, disttable.temp
   Presorted Key: disttable.device
   ->  WindowAgg
         Output: disttable.device, disttable.temp, avg(disttable.temp) OVER (?)
         ->  Custom Scan (AsyncAppend)
               Output: disttable.device, disttable.temp
               ->  Merge Append
                     Sort Key: disttable_1.device
                     ->  Custom Scan (DataNodeScan) on public.disttable disttable_1
                           Output: disttable_1.device, disttable_1.temp
                           Data node: db_dist_hypertable_1
                           Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_6_chunk
                           Remote SQL: SELECT device, temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2, 3]) ORDER BY device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.disttable disttable_2
                           Output: disttable_2.device, disttable_2.temp
                           Data node: db_dist_hypertable_2
                           Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_3_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_7_chunk
                           Remote SQL: SELECT device, temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2, 3, 4]) ORDER BY device ASC NULLS LAST
(20 rows)

SELECT device, temp, avg(temp) OVER (PARTITION BY device)
FROM disttable
ORDER BY device, temp;
 device | temp |       avg        
--------+------+------------------
      1 |  1.1 | 1.23333333333333
      1 |  1.2 | 1.23333333333333
      1 |  1.4 | 1.23333333333333
      2 |  1.3 |              1.4
      2 |  1.4 |              1.4
      2 |  1.5 |              1.4
      3 |  2.1 |              2.2
      3 |  2.2 |              2.2
      3 |  2.3 |              2.2
     13 |  1.4 | 1.43333333333333
     13 |  1.4 | 1.43333333333333
     13 |  1.5 | 1.43333333333333
     29 |  1.2 |             1.35
     29 |  1.5 |             1.35
     87 |  1.4 |              1.6
     87 |  1.6 |              1.6
     87 |  1.8 |              1.6
     90 |  2.7 |             2.75
     90 |  2.8 |             2.75
(19 rows)

-- Test remote explain
-- Make sure that chunks_in function only expects one-dimensional integer arrays
\set ON_ERROR_STOP 0
SELECT "time" FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[[2], [1]])
ORDER BY "time" DESC NULLS FIRST LIMIT 1;
ERROR:  invalid number of array dimensions for chunks_in
\set ON_ERROR_STOP 1
SET timescaledb.enable_remote_explain = ON;
-- Check that datanodes use ChunkAppend plans with chunks_in function in the
-- "Remote SQL" when using max(time).
EXPLAIN (VERBOSE, COSTS FALSE)
SELECT max(time)
FROM disttable;
                                                                                                          QUERY PLAN                                                                                                          
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Result
   Output: $0
   InitPlan 1 (returns $0)
     ->  Limit
           Output: disttable."time"
           ->  Custom Scan (AsyncAppend)
                 Output: disttable."time"
                 ->  Merge Append
                       Sort Key: disttable_1."time" DESC
                       ->  Custom Scan (DataNodeScan) on public.disttable disttable_1
                             Output: disttable_1."time"
                             Data node: db_dist_hypertable_1
                             Chunks: _dist_hyper_1_6_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_1_chunk
                             Remote SQL: SELECT "time" FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[3, 2, 1]) AND (("time" IS NOT NULL)) ORDER BY "time" DESC NULLS FIRST LIMIT 1
                             Remote EXPLAIN: 
                               Limit
                                 Output: disttable."time"
                                 ->  Custom Scan (ChunkAppend) on public.disttable
                                       Output: disttable."time"
                                       Order: disttable."time" DESC
                                       Startup Exclusion: false
                                       Runtime Exclusion: false
                                       ->  Merge Append
                                             Sort Key: _dist_hyper_1_6_chunk."time" DESC
                                             ->  Index Only Scan using _dist_hyper_1_6_chunk_disttable_time_idx on _timescaledb_internal._dist_hyper_1_6_chunk
                                                   Output: _dist_hyper_1_6_chunk."time"
                                                   Index Cond: (_dist_hyper_1_6_chunk."time" IS NOT NULL)
                                             ->  Index Only Scan using _dist_hyper_1_5_chunk_disttable_time_idx on _timescaledb_internal._dist_hyper_1_5_chunk
                                                   Output: _dist_hyper_1_5_chunk."time"
                                                   Index Cond: (_dist_hyper_1_5_chunk."time" IS NOT NULL)
                                       ->  Index Only Scan using _dist_hyper_1_1_chunk_disttable_time_idx on _timescaledb_internal._dist_hyper_1_1_chunk
                                             Output: _dist_hyper_1_1_chunk."time"
                                             Index Cond: (_dist_hyper_1_1_chunk."time" IS NOT NULL)
 
                       ->  Custom Scan (DataNodeScan) on public.disttable disttable_2
                             Output: disttable_2."time"
                             Data node: db_dist_hypertable_2
                             Chunks: _dist_hyper_1_7_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_3_chunk, _dist_hyper_1_2_chunk
                             Remote SQL: SELECT "time" FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[4, 3, 2, 1]) AND (("time" IS NOT NULL)) ORDER BY "time" DESC NULLS FIRST LIMIT 1
                             Remote EXPLAIN: 
                               Limit
                                 Output: disttable."time"
                                 ->  Custom Scan (ChunkAppend) on public.disttable
                                       Output: disttable."time"
                                       Order: disttable."time" DESC
                                       Startup Exclusion: false
                                       Runtime Exclusion: false
                                       ->  Merge Append
                                             Sort Key: _dist_hyper_1_7_chunk."time" DESC
                                             ->  Index Only Scan using _dist_hyper_1_7_chunk_disttable_time_idx on _timescaledb_internal._dist_hyper_1_7_chunk
                                                   Output: _dist_hyper_1_7_chunk."time"
                                                   Index Cond: (_dist_hyper_1_7_chunk."time" IS NOT NULL)
                                             ->  Index Only Scan using _dist_hyper_1_4_chunk_disttable_time_idx on _timescaledb_internal._dist_hyper_1_4_chunk
                                                   Output: _dist_hyper_1_4_chunk."time"
                                                   Index Cond: (_dist_hyper_1_4_chunk."time" IS NOT NULL)
                                       ->  Merge Append
                                             Sort Key: _dist_hyper_1_3_chunk."time" DESC
                                             ->  Index Only Scan using _dist_hyper_1_3_chunk_disttable_time_idx on _timescaledb_internal._dist_hyper_1_3_chunk
                                                   Output: _dist_hyper_1_3_chunk."time"
                                                   Index Cond: (_dist_hyper_1_3_chunk."time" IS NOT NULL)
                                             ->  Index Only Scan using _dist_hyper_1_2_chunk_disttable_time_idx on _timescaledb_internal._dist_hyper_1_2_chunk
                                                   Output: _dist_hyper_1_2_chunk."time"
                                                   Index Cond: (_dist_hyper_1_2_chunk."time" IS NOT NULL)
 
(64 rows)

EXPLAIN (VERBOSE, COSTS FALSE)
SELECT max(temp)
FROM disttable;
                                                                                                       QUERY PLAN                                                                                                       
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Result
   Output: $0
   InitPlan 1 (returns $0)
     ->  Limit
           Output: disttable.temp
           ->  Custom Scan (AsyncAppend)
                 Output: disttable.temp
                 ->  Merge Append
                       Sort Key: disttable_1.temp DESC
                       ->  Custom Scan (DataNodeScan) on public.disttable disttable_1
                             Output: disttable_1.temp
                             Data node: db_dist_hypertable_1
                             Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_6_chunk
                             Remote SQL: SELECT temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2, 3]) AND ((temp IS NOT NULL)) ORDER BY temp DESC NULLS FIRST LIMIT 1
                             Remote EXPLAIN: 
                               Limit
                                 Output: _dist_hyper_1_1_chunk.temp
                                 ->  Sort
                                       Output: _dist_hyper_1_1_chunk.temp
                                       Sort Key: _dist_hyper_1_1_chunk.temp DESC
                                       ->  Append
                                             ->  Seq Scan on _timescaledb_internal._dist_hyper_1_1_chunk
                                                   Output: _dist_hyper_1_1_chunk.temp
                                                   Filter: (_dist_hyper_1_1_chunk.temp IS NOT NULL)
                                             ->  Seq Scan on _timescaledb_internal._dist_hyper_1_5_chunk
                                                   Output: _dist_hyper_1_5_chunk.temp
                                                   Filter: (_dist_hyper_1_5_chunk.temp IS NOT NULL)
                                             ->  Seq Scan on _timescaledb_internal._dist_hyper_1_6_chunk
                                                   Output: _dist_hyper_1_6_chunk.temp
                                                   Filter: (_dist_hyper_1_6_chunk.temp IS NOT NULL)
 
                       ->  Custom Scan (DataNodeScan) on public.disttable disttable_2
                             Output: disttable_2.temp
                             Data node: db_dist_hypertable_2
                             Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_3_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_7_chunk
                             Remote SQL: SELECT temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2, 3, 4]) AND ((temp IS NOT NULL)) ORDER BY temp DESC NULLS FIRST LIMIT 1
                             Remote EXPLAIN: 
                               Limit
                                 Output: _dist_hyper_1_2_chunk.temp
                                 ->  Sort
                                       Output: _dist_hyper_1_2_chunk.temp
                                       Sort Key: _dist_hyper_1_2_chunk.temp DESC
                                       ->  Append
                                             ->  Seq Scan on _timescaledb_internal._dist_hyper_1_2_chunk
                                                   Output: _dist_hyper_1_2_chunk.temp
                                                   Filter: (_dist_hyper_1_2_chunk.temp IS NOT NULL)
                                             ->  Seq Scan on _timescaledb_internal._dist_hyper_1_3_chunk
                                                   Output: _dist_hyper_1_3_chunk.temp
                                                   Filter: (_dist_hyper_1_3_chunk.temp IS NOT NULL)
                                             ->  Seq Scan on _timescaledb_internal._dist_hyper_1_4_chunk
                                                   Output: _dist_hyper_1_4_chunk.temp
                                                   Filter: (_dist_hyper_1_4_chunk.temp IS NOT NULL)
                                             ->  Seq Scan on _timescaledb_internal._dist_hyper_1_7_chunk
                                                   Output: _dist_hyper_1_7_chunk.temp
                                                   Filter: (_dist_hyper_1_7_chunk.temp IS NOT NULL)
 
(56 rows)

-- Don't remote explain if there is no VERBOSE flag
EXPLAIN (COSTS FALSE)
SELECT max(temp)
FROM disttable;
                                  QUERY PLAN                                   
-------------------------------------------------------------------------------
 Result
   InitPlan 1 (returns $0)
     ->  Limit
           ->  Custom Scan (AsyncAppend)
                 ->  Merge Append
                       Sort Key: disttable_1.temp DESC
                       ->  Custom Scan (DataNodeScan) on disttable disttable_1
                       ->  Custom Scan (DataNodeScan) on disttable disttable_2
(8 rows)

-- Test additional EXPLAIN flags
EXPLAIN (ANALYZE, VERBOSE, COSTS FALSE, BUFFERS OFF, TIMING OFF, SUMMARY OFF)
SELECT max(temp)
FROM disttable;
                                                                                                       QUERY PLAN                                                                                                       
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Result (actual rows=1 loops=1)
   Output: $0
   InitPlan 1 (returns $0)
     ->  Limit (actual rows=1 loops=1)
           Output: disttable.temp
           ->  Custom Scan (AsyncAppend) (actual rows=1 loops=1)
                 Output: disttable.temp
                 ->  Merge Append (actual rows=1 loops=1)
                       Sort Key: disttable_1.temp DESC
                       ->  Custom Scan (DataNodeScan) on public.disttable disttable_1 (actual rows=1 loops=1)
                             Output: disttable_1.temp
                             Data node: db_dist_hypertable_1
                             Fetcher Type: COPY
                             Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_6_chunk
                             Remote SQL: SELECT temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2, 3]) AND ((temp IS NOT NULL)) ORDER BY temp DESC NULLS FIRST LIMIT 1
                             Remote EXPLAIN: 
                               Limit (actual rows=1 loops=1)
                                 Output: _dist_hyper_1_1_chunk.temp
                                 ->  Sort (actual rows=1 loops=1)
                                       Output: _dist_hyper_1_1_chunk.temp
                                       Sort Key: _dist_hyper_1_1_chunk.temp DESC
                                       Sort Method: top-N heapsort 
                                       ->  Append (actual rows=8 loops=1)
                                             ->  Seq Scan on _timescaledb_internal._dist_hyper_1_1_chunk (actual rows=3 loops=1)
                                                   Output: _dist_hyper_1_1_chunk.temp
                                                   Filter: (_dist_hyper_1_1_chunk.temp IS NOT NULL)
                                             ->  Seq Scan on _timescaledb_internal._dist_hyper_1_5_chunk (actual rows=3 loops=1)
                                                   Output: _dist_hyper_1_5_chunk.temp
                                                   Filter: (_dist_hyper_1_5_chunk.temp IS NOT NULL)
                                             ->  Seq Scan on _timescaledb_internal._dist_hyper_1_6_chunk (actual rows=2 loops=1)
                                                   Output: _dist_hyper_1_6_chunk.temp
                                                   Filter: (_dist_hyper_1_6_chunk.temp IS NOT NULL)
 
                       ->  Custom Scan (DataNodeScan) on public.disttable disttable_2 (actual rows=1 loops=1)
                             Output: disttable_2.temp
                             Data node: db_dist_hypertable_2
                             Fetcher Type: COPY
                             Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_3_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_7_chunk
                             Remote SQL: SELECT temp FROM public.disttable WHERE _timescaledb_internal.chunks_in(public.disttable.*, ARRAY[1, 2, 3, 4]) AND ((temp IS NOT NULL)) ORDER BY temp DESC NULLS FIRST LIMIT 1
                             Remote EXPLAIN: 
                               Limit (actual rows=1 loops=1)
                                 Output: _dist_hyper_1_2_chunk.temp
                                 ->  Sort (actual rows=1 loops=1)
                                       Output: _dist_hyper_1_2_chunk.temp
                                       Sort Key: _dist_hyper_1_2_chunk.temp DESC
                                       Sort Method: top-N heapsort 
                                       ->  Append (actual rows=11 loops=1)
                                             ->  Seq Scan on _timescaledb_internal._dist_hyper_1_2_chunk (actual rows=3 loops=1)
                                                   Output: _dist_hyper_1_2_chunk.temp
                                                   Filter: (_dist_hyper_1_2_chunk.temp IS NOT NULL)
                                             ->  Seq Scan on _timescaledb_internal._dist_hyper_1_3_chunk (actual rows=3 loops=1)
                                                   Output: _dist_hyper_1_3_chunk.temp
                                                   Filter: (_dist_hyper_1_3_chunk.temp IS NOT NULL)
                                             ->  Seq Scan on _timescaledb_internal._dist_hyper_1_4_chunk (actual rows=3 loops=1)
                                                   Output: _dist_hyper_1_4_chunk.temp
                                                   Filter: (_dist_hyper_1_4_chunk.temp IS NOT NULL)
                                             ->  Seq Scan on _timescaledb_internal._dist_hyper_1_7_chunk (actual rows=2 loops=1)
                                                   Output: _dist_hyper_1_7_chunk.temp
                                                   Filter: (_dist_hyper_1_7_chunk.temp IS NOT NULL)
 
(60 rows)

-- The constraints, indexes, and triggers on foreign chunks. Only
-- check constraints should recurse to foreign chunks (although they
-- aren't enforced on a foreign table)
SELECT st."Child" as chunk_relid, test.show_constraints((st)."Child")
FROM test.show_subtables('disttable') st;
                 chunk_relid                 |                                                                                   show_constraints                                                                                   
---------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 _timescaledb_internal._dist_hyper_1_1_chunk | (constraint_1,c,{time},-,"((""time"" >= 'Wed Dec 28 16:00:00 2016 PST'::timestamp with time zone) AND (""time"" < 'Wed Jan 04 16:00:00 2017 PST'::timestamp with time zone))",f,f,t)
 _timescaledb_internal._dist_hyper_1_1_chunk | (constraint_2,c,{device},-,"(_timescaledb_internal.get_partition_hash(device) < 268435455)",f,f,t)
 _timescaledb_internal._dist_hyper_1_1_chunk | (disttable_device_check,c,{device},-,"(device > 0)",f,f,t)
 _timescaledb_internal._dist_hyper_1_2_chunk | (constraint_1,c,{time},-,"((""time"" >= 'Wed Dec 28 16:00:00 2016 PST'::timestamp with time zone) AND (""time"" < 'Wed Jan 04 16:00:00 2017 PST'::timestamp with time zone))",f,f,t)
 _timescaledb_internal._dist_hyper_1_2_chunk | (constraint_3,c,{device},-,"(_timescaledb_internal.get_partition_hash(device) >= 1879048185)",f,f,t)
 _timescaledb_internal._dist_hyper_1_2_chunk | (disttable_device_check,c,{device},-,"(device > 0)",f,f,t)
 _timescaledb_internal._dist_hyper_1_3_chunk | (constraint_1,c,{time},-,"((""time"" >= 'Wed Dec 28 16:00:00 2016 PST'::timestamp with time zone) AND (""time"" < 'Wed Jan 04 16:00:00 2017 PST'::timestamp with time zone))",f,f,t)
 _timescaledb_internal._dist_hyper_1_3_chunk | (constraint_4,c,{device},-,"((_timescaledb_internal.get_partition_hash(device) >= 1073741820) AND (_timescaledb_internal.get_partition_hash(device) < 1342177275))",f,f,t)
 _timescaledb_internal._dist_hyper_1_3_chunk | (disttable_device_check,c,{device},-,"(device > 0)",f,f,t)
 _timescaledb_internal._dist_hyper_1_4_chunk | (constraint_5,c,{time},-,"((""time"" >= 'Wed Jun 27 17:00:00 2018 PDT'::timestamp with time zone) AND (""time"" < 'Wed Jul 04 17:00:00 2018 PDT'::timestamp with time zone))",f,f,t)
 _timescaledb_internal._dist_hyper_1_4_chunk | (constraint_6,c,{device},-,"((_timescaledb_internal.get_partition_hash(device) >= 268435455) AND (_timescaledb_internal.get_partition_hash(device) < 536870910))",f,f,t)
 _timescaledb_internal._dist_hyper_1_4_chunk | (disttable_device_check,c,{device},-,"(device > 0)",f,f,t)
 _timescaledb_internal._dist_hyper_1_5_chunk | (constraint_5,c,{time},-,"((""time"" >= 'Wed Jun 27 17:00:00 2018 PDT'::timestamp with time zone) AND (""time"" < 'Wed Jul 04 17:00:00 2018 PDT'::timestamp with time zone))",f,f,t)
 _timescaledb_internal._dist_hyper_1_5_chunk | (constraint_7,c,{device},-,"((_timescaledb_internal.get_partition_hash(device) >= 805306365) AND (_timescaledb_internal.get_partition_hash(device) < 1073741820))",f,f,t)
 _timescaledb_internal._dist_hyper_1_5_chunk | (disttable_device_check,c,{device},-,"(device > 0)",f,f,t)
 _timescaledb_internal._dist_hyper_1_6_chunk | (constraint_5,c,{time},-,"((""time"" >= 'Wed Jun 27 17:00:00 2018 PDT'::timestamp with time zone) AND (""time"" < 'Wed Jul 04 17:00:00 2018 PDT'::timestamp with time zone))",f,f,t)
 _timescaledb_internal._dist_hyper_1_6_chunk | (constraint_8,c,{device},-,"((_timescaledb_internal.get_partition_hash(device) >= 1610612730) AND (_timescaledb_internal.get_partition_hash(device) < 1879048185))",f,f,t)
 _timescaledb_internal._dist_hyper_1_6_chunk | (disttable_device_check,c,{device},-,"(device > 0)",f,f,t)
 _timescaledb_internal._dist_hyper_1_7_chunk | (constraint_3,c,{device},-,"(_timescaledb_internal.get_partition_hash(device) >= 1879048185)",f,f,t)
 _timescaledb_internal._dist_hyper_1_7_chunk | (constraint_5,c,{time},-,"((""time"" >= 'Wed Jun 27 17:00:00 2018 PDT'::timestamp with time zone) AND (""time"" < 'Wed Jul 04 17:00:00 2018 PDT'::timestamp with time zone))",f,f,t)
 _timescaledb_internal._dist_hyper_1_7_chunk | (disttable_device_check,c,{device},-,"(device > 0)",f,f,t)
(21 rows)

SELECT st."Child" as chunk_relid, test.show_indexes((st)."Child")
FROM test.show_subtables('disttable') st;
 chunk_relid | show_indexes 
-------------+--------------
(0 rows)

SELECT st."Child" as chunk_relid, test.show_triggers((st)."Child")
FROM test.show_subtables('disttable') st;
 chunk_relid | show_triggers 
-------------+---------------
(0 rows)

-- Check that the chunks are assigned data nodes
SELECT * FROM _timescaledb_catalog.chunk_data_node ORDER BY 1,2,3;
 chunk_id | node_chunk_id |      node_name       
----------+---------------+----------------------
        1 |             1 | db_dist_hypertable_1
        2 |             1 | db_dist_hypertable_2
        3 |             2 | db_dist_hypertable_2
        4 |             3 | db_dist_hypertable_2
        5 |             2 | db_dist_hypertable_1
        6 |             3 | db_dist_hypertable_1
        7 |             4 | db_dist_hypertable_2
(7 rows)

-- Adding a new trigger should not recurse to foreign chunks
CREATE TRIGGER _1_test_trigger_insert
    AFTER INSERT ON disttable
    FOR EACH ROW EXECUTE FUNCTION test_trigger();
SELECT st."Child" as chunk_relid, test.show_triggers((st)."Child")
FROM test.show_subtables('disttable') st;
 chunk_relid | show_triggers 
-------------+---------------
(0 rows)

-- Check that we can create indexes on distributed hypertables and
-- that they don't recurse to foreign chunks
CREATE INDEX ON disttable (time, device);
SELECT * FROM test.show_indexes('disttable');
           Index           |    Columns    | Expr | Unique | Primary | Exclusion | Tablespace 
---------------------------+---------------+------+--------+---------+-----------+------------
 disttable_device_time_idx | {device,time} |      | f      | f       | f         | 
 disttable_pkey            | {time,device} |      | t      | t       | f         | 
 disttable_time_device_idx | {time,device} |      | f      | f       | f         | 
 disttable_time_idx        | {time}        |      | f      | f       | f         | 
(4 rows)

SELECT st."Child" as chunk_relid, test.show_indexes((st)."Child")
FROM test.show_subtables('disttable') st;
 chunk_relid | show_indexes 
-------------+--------------
(0 rows)

-- No index mappings should exist either
SELECT * FROM _timescaledb_catalog.chunk_index;
 chunk_id | index_name | hypertable_id | hypertable_index_name 
----------+------------+---------------+-----------------------
(0 rows)

-- Check that creating columns work
ALTER TABLE disttable ADD COLUMN "Color" int;
SELECT * FROM test.show_columns('disttable');
 Column |           Type           | NotNull 
--------+--------------------------+---------
 time   | timestamp with time zone | t
 device | integer                  | t
 temp   | double precision         | f
 Color  | integer                  | f
(4 rows)

SELECT st."Child" as chunk_relid, test.show_columns((st)."Child")
FROM test.show_subtables('disttable') st;
                 chunk_relid                 |            show_columns             
---------------------------------------------+-------------------------------------
 _timescaledb_internal._dist_hyper_1_1_chunk | (time,"timestamp with time zone",t)
 _timescaledb_internal._dist_hyper_1_1_chunk | (device,integer,t)
 _timescaledb_internal._dist_hyper_1_1_chunk | (temp,"double precision",f)
 _timescaledb_internal._dist_hyper_1_1_chunk | (Color,integer,f)
 _timescaledb_internal._dist_hyper_1_2_chunk | (time,"timestamp with time zone",t)
 _timescaledb_internal._dist_hyper_1_2_chunk | (device,integer,t)
 _timescaledb_internal._dist_hyper_1_2_chunk | (temp,"double precision",f)
 _timescaledb_internal._dist_hyper_1_2_chunk | (Color,integer,f)
 _timescaledb_internal._dist_hyper_1_3_chunk | (time,"timestamp with time zone",t)
 _timescaledb_internal._dist_hyper_1_3_chunk | (device,integer,t)
 _timescaledb_internal._dist_hyper_1_3_chunk | (temp,"double precision",f)
 _timescaledb_internal._dist_hyper_1_3_chunk | (Color,integer,f)
 _timescaledb_internal._dist_hyper_1_4_chunk | (time,"timestamp with time zone",t)
 _timescaledb_internal._dist_hyper_1_4_chunk | (device,integer,t)
 _timescaledb_internal._dist_hyper_1_4_chunk | (temp,"double precision",f)
 _timescaledb_internal._dist_hyper_1_4_chunk | (Color,integer,f)
 _timescaledb_internal._dist_hyper_1_5_chunk | (time,"timestamp with time zone",t)
 _timescaledb_internal._dist_hyper_1_5_chunk | (device,integer,t)
 _timescaledb_internal._dist_hyper_1_5_chunk | (temp,"double precision",f)
 _timescaledb_internal._dist_hyper_1_5_chunk | (Color,integer,f)
 _timescaledb_internal._dist_hyper_1_6_chunk | (time,"timestamp with time zone",t)
 _timescaledb_internal._dist_hyper_1_6_chunk | (device,integer,t)
 _timescaledb_internal._dist_hyper_1_6_chunk | (temp,"double precision",f)
 _timescaledb_internal._dist_hyper_1_6_chunk | (Color,integer,f)
 _timescaledb_internal._dist_hyper_1_7_chunk | (time,"timestamp with time zone",t)
 _timescaledb_internal._dist_hyper_1_7_chunk | (device,integer,t)
 _timescaledb_internal._dist_hyper_1_7_chunk | (temp,"double precision",f)
 _timescaledb_internal._dist_hyper_1_7_chunk | (Color,integer,f)
(28 rows)

-- Adding a new unique constraint should not recurse to foreign
-- chunks, but a check constraint should
ALTER TABLE disttable ADD CONSTRAINT disttable_color_unique UNIQUE (time, device, "Color");
ALTER TABLE disttable ADD CONSTRAINT disttable_temp_non_negative CHECK (temp > 0.0);
SELECT st."Child" as chunk_relid, test.show_constraints((st)."Child")
FROM test.show_subtables('disttable') st;
                 chunk_relid                 |                                                                                   show_constraints                                                                                   
---------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 _timescaledb_internal._dist_hyper_1_1_chunk | (constraint_1,c,{time},-,"((""time"" >= 'Wed Dec 28 16:00:00 2016 PST'::timestamp with time zone) AND (""time"" < 'Wed Jan 04 16:00:00 2017 PST'::timestamp with time zone))",f,f,t)
 _timescaledb_internal._dist_hyper_1_1_chunk | (constraint_2,c,{device},-,"(_timescaledb_internal.get_partition_hash(device) < 268435455)",f,f,t)
 _timescaledb_internal._dist_hyper_1_1_chunk | (disttable_device_check,c,{device},-,"(device > 0)",f,f,t)
 _timescaledb_internal._dist_hyper_1_1_chunk | (disttable_temp_non_negative,c,{temp},-,"(temp > (0.0)::double precision)",f,f,t)
 _timescaledb_internal._dist_hyper_1_2_chunk | (constraint_1,c,{time},-,"((""time"" >= 'Wed Dec 28 16:00:00 2016 PST'::timestamp with time zone) AND (""time"" < 'Wed Jan 04 16:00:00 2017 PST'::timestamp with time zone))",f,f,t)
 _timescaledb_internal._dist_hyper_1_2_chunk | (constraint_3,c,{device},-,"(_timescaledb_internal.get_partition_hash(device) >= 1879048185)",f,f,t)
 _timescaledb_internal._dist_hyper_1_2_chunk | (disttable_device_check,c,{device},-,"(device > 0)",f,f,t)
 _timescaledb_internal._dist_hyper_1_2_chunk | (disttable_temp_non_negative,c,{temp},-,"(temp > (0.0)::double precision)",f,f,t)
 _timescaledb_internal._dist_hyper_1_3_chunk | (constraint_1,c,{time},-,"((""time"" >= 'Wed Dec 28 16:00:00 2016 PST'::timestamp with time zone) AND (""time"" < 'Wed Jan 04 16:00:00 2017 PST'::timestamp with time zone))",f,f,t)
 _timescaledb_internal._dist_hyper_1_3_chunk | (constraint_4,c,{device},-,"((_timescaledb_internal.get_partition_hash(device) >= 1073741820) AND (_timescaledb_internal.get_partition_hash(device) < 1342177275))",f,f,t)
 _timescaledb_internal._dist_hyper_1_3_chunk | (disttable_device_check,c,{device},-,"(device > 0)",f,f,t)
 _timescaledb_internal._dist_hyper_1_3_chunk | (disttable_temp_non_negative,c,{temp},-,"(temp > (0.0)::double precision)",f,f,t)
 _timescaledb_internal._dist_hyper_1_4_chunk | (constraint_5,c,{time},-,"((""time"" >= 'Wed Jun 27 17:00:00 2018 PDT'::timestamp with time zone) AND (""time"" < 'Wed Jul 04 17:00:00 2018 PDT'::timestamp with time zone))",f,f,t)
 _timescaledb_internal._dist_hyper_1_4_chunk | (constraint_6,c,{device},-,"((_timescaledb_internal.get_partition_hash(device) >= 268435455) AND (_timescaledb_internal.get_partition_hash(device) < 536870910))",f,f,t)
 _timescaledb_internal._dist_hyper_1_4_chunk | (disttable_device_check,c,{device},-,"(device > 0)",f,f,t)
 _timescaledb_internal._dist_hyper_1_4_chunk | (disttable_temp_non_negative,c,{temp},-,"(temp > (0.0)::double precision)",f,f,t)
 _timescaledb_internal._dist_hyper_1_5_chunk | (constraint_5,c,{time},-,"((""time"" >= 'Wed Jun 27 17:00:00 2018 PDT'::timestamp with time zone) AND (""time"" < 'Wed Jul 04 17:00:00 2018 PDT'::timestamp with time zone))",f,f,t)
 _timescaledb_internal._dist_hyper_1_5_chunk | (constraint_7,c,{device},-,"((_timescaledb_internal.get_partition_hash(device) >= 805306365) AND (_timescaledb_internal.get_partition_hash(device) < 1073741820))",f,f,t)
 _timescaledb_internal._dist_hyper_1_5_chunk | (disttable_device_check,c,{device},-,"(device > 0)",f,f,t)
 _timescaledb_internal._dist_hyper_1_5_chunk | (disttable_temp_non_negative,c,{temp},-,"(temp > (0.0)::double precision)",f,f,t)
 _timescaledb_internal._dist_hyper_1_6_chunk | (constraint_5,c,{time},-,"((""time"" >= 'Wed Jun 27 17:00:00 2018 PDT'::timestamp with time zone) AND (""time"" < 'Wed Jul 04 17:00:00 2018 PDT'::timestamp with time zone))",f,f,t)
 _timescaledb_internal._dist_hyper_1_6_chunk | (constraint_8,c,{device},-,"((_timescaledb_internal.get_partition_hash(device) >= 1610612730) AND (_timescaledb_internal.get_partition_hash(device) < 1879048185))",f,f,t)
 _timescaledb_internal._dist_hyper_1_6_chunk | (disttable_device_check,c,{device},-,"(device > 0)",f,f,t)
 _timescaledb_internal._dist_hyper_1_6_chunk | (disttable_temp_non_negative,c,{temp},-,"(temp > (0.0)::double precision)",f,f,t)
 _timescaledb_internal._dist_hyper_1_7_chunk | (constraint_3,c,{device},-,"(_timescaledb_internal.get_partition_hash(device) >= 1879048185)",f,f,t)
 _timescaledb_internal._dist_hyper_1_7_chunk | (constraint_5,c,{time},-,"((""time"" >= 'Wed Jun 27 17:00:00 2018 PDT'::timestamp with time zone) AND (""time"" < 'Wed Jul 04 17:00:00 2018 PDT'::timestamp with time zone))",f,f,t)
 _timescaledb_internal._dist_hyper_1_7_chunk | (disttable_device_check,c,{device},-,"(device > 0)",f,f,t)
 _timescaledb_internal._dist_hyper_1_7_chunk | (disttable_temp_non_negative,c,{temp},-,"(temp > (0.0)::double precision)",f,f,t)
(28 rows)

SELECT cc.*
FROM (SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
      FROM show_chunks('disttable')) c,
      _timescaledb_catalog.chunk_constraint cc
WHERE c.chunk_id = cc.chunk_id;
 chunk_id | dimension_slice_id | constraint_name | hypertable_constraint_name 
----------+--------------------+-----------------+----------------------------
        1 |                  2 | constraint_2    | 
        1 |                  1 | constraint_1    | 
        2 |                  3 | constraint_3    | 
        2 |                  1 | constraint_1    | 
        3 |                  4 | constraint_4    | 
        3 |                  1 | constraint_1    | 
        4 |                  6 | constraint_6    | 
        4 |                  5 | constraint_5    | 
        5 |                  7 | constraint_7    | 
        5 |                  5 | constraint_5    | 
        6 |                  8 | constraint_8    | 
        6 |                  5 | constraint_5    | 
        7 |                  3 | constraint_3    | 
        7 |                  5 | constraint_5    | 
(14 rows)

-- Show contents after re-adding column
SELECT * FROM disttable;
             time             | device | temp | Color 
------------------------------+--------+------+-------
 Sun Jan 01 06:01:00 2017 PST |      1 |  1.1 |      
 Sun Jan 01 08:01:00 2017 PST |      1 |  1.2 |      
 Sun Jan 01 06:05:00 2017 PST |      1 |  1.4 |      
 Sun Jul 01 06:01:00 2018 PDT |     13 |  1.4 |      
 Sun Jul 01 06:21:00 2018 PDT |     13 |  1.5 |      
 Sun Jul 01 07:01:00 2018 PDT |     13 |  1.4 |      
 Sun Jul 01 09:11:00 2018 PDT |     90 |  2.7 |      
 Sun Jul 01 09:21:00 2018 PDT |     90 |  2.8 |      
 Sun Jan 01 09:11:00 2017 PST |      3 |  2.1 |      
 Sun Jan 01 09:21:00 2017 PST |      3 |  2.2 |      
 Sun Jan 01 08:11:00 2017 PST |      3 |  2.3 |      
 Mon Jan 02 08:01:00 2017 PST |      2 |  1.3 |      
 Mon Jan 02 09:01:00 2017 PST |      2 |  1.4 |      
 Mon Jan 02 08:21:00 2017 PST |      2 |  1.5 |      
 Mon Jul 02 08:01:00 2018 PDT |     87 |  1.6 |      
 Mon Jul 02 09:01:00 2018 PDT |     87 |  1.4 |      
 Mon Jul 02 09:21:00 2018 PDT |     87 |  1.8 |      
 Sun Jul 01 08:01:00 2018 PDT |     29 |  1.5 |      
 Sun Jul 01 08:21:00 2018 PDT |     29 |  1.2 |      
(19 rows)

-- Test INSERTS with RETURNING. Since we previously dropped a column
-- on the hypertable, this also tests that we handle conversion of the
-- attribute numbers in the RETURNING clause, since they now differ
-- between the hypertable root relation and the chunk currently
-- RETURNING from.
INSERT INTO disttable (time, device, "Color", temp)
VALUES ('2017-09-02 06:09', 4, 1, 9.8)
RETURNING time, "Color", temp;
             time             | Color | temp 
------------------------------+-------+------
 Sat Sep 02 06:09:00 2017 PDT |     1 |  9.8
(1 row)

INSERT INTO disttable (time, device, "Color", temp)
VALUES ('2017-09-03 06:18', 9, 3, 8.7)
RETURNING 1;
 ?column? 
----------
        1
(1 row)

-- On conflict
INSERT INTO disttable (time, device, "Color", temp)
VALUES ('2017-09-02 06:09', 6, 2, 10.5)
ON CONFLICT DO NOTHING;
SELECT * FROM test.remote_exec(ARRAY[:'DATA_NODE_1', :'DATA_NODE_2', :'DATA_NODE_3'], $$
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable');
$$);
NOTICE:  [db_dist_hypertable_1]: 
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable')
NOTICE:  [db_dist_hypertable_1]:
chunk_id|hypertable_id|schema_name          |table_name           |relkind|slices                                                                                     
--------+-------------+---------------------+---------------------+-------+-------------------------------------------------------------------------------------------
       1|            1|_timescaledb_internal|_dist_hyper_1_1_chunk|r      |{"time": [1482969600000000, 1483574400000000], "device": [-9223372036854775808, 268435455]}
       2|            1|_timescaledb_internal|_dist_hyper_1_5_chunk|r      |{"time": [1530144000000000, 1530748800000000], "device": [805306365, 1073741820]}          
       3|            1|_timescaledb_internal|_dist_hyper_1_6_chunk|r      |{"time": [1530144000000000, 1530748800000000], "device": [1610612730, 1879048185]}         
       4|            1|_timescaledb_internal|_dist_hyper_1_9_chunk|r      |{"time": [1504137600000000, 1504742400000000], "device": [1610612730, 1879048185]}         
(4 rows)


NOTICE:  [db_dist_hypertable_2]: 
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable')
NOTICE:  [db_dist_hypertable_2]:
chunk_id|hypertable_id|schema_name          |table_name           |relkind|slices                                                                                     
--------+-------------+---------------------+---------------------+-------+-------------------------------------------------------------------------------------------
       1|            1|_timescaledb_internal|_dist_hyper_1_2_chunk|r      |{"time": [1482969600000000, 1483574400000000], "device": [1879048185, 9223372036854775807]}
       2|            1|_timescaledb_internal|_dist_hyper_1_3_chunk|r      |{"time": [1482969600000000, 1483574400000000], "device": [1073741820, 1342177275]}         
       3|            1|_timescaledb_internal|_dist_hyper_1_4_chunk|r      |{"time": [1530144000000000, 1530748800000000], "device": [268435455, 536870910]}           
       4|            1|_timescaledb_internal|_dist_hyper_1_7_chunk|r      |{"time": [1530144000000000, 1530748800000000], "device": [1879048185, 9223372036854775807]}
       5|            1|_timescaledb_internal|_dist_hyper_1_8_chunk|r      |{"time": [1504137600000000, 1504742400000000], "device": [1073741820, 1342177275]}         
(5 rows)


NOTICE:  [db_dist_hypertable_3]: 
SELECT (_timescaledb_internal.show_chunk(show_chunks)).*
FROM show_chunks('disttable')
NOTICE:  [db_dist_hypertable_3]:
chunk_id|hypertable_id|schema_name          |table_name            |relkind|slices                                                                          
--------+-------------+---------------------+----------------------+-------+--------------------------------------------------------------------------------
       1|            1|_timescaledb_internal|_dist_hyper_1_10_chunk|r      |{"time": [1504137600000000, 1504742400000000], "device": [536870910, 805306365]}
(1 row)


 remote_exec 
-------------
 
(1 row)

-- Show new row and that conflicting row is not inserted
SELECT * FROM test.remote_exec(ARRAY[:'DATA_NODE_1', :'DATA_NODE_2', :'DATA_NODE_3'], $$
SELECT * FROM disttable;
$$);
NOTICE:  [db_dist_hypertable_1]: 
SELECT * FROM disttable
NOTICE:  [db_dist_hypertable_1]:
time                        |device|temp|Color
----------------------------+------+----+-----
Sun Jan 01 06:01:00 2017 PST|     1| 1.1|     
Sun Jan 01 08:01:00 2017 PST|     1| 1.2|     
Sun Jan 01 06:05:00 2017 PST|     1| 1.4|     
Sun Jul 01 06:01:00 2018 PDT|    13| 1.4|     
Sun Jul 01 06:21:00 2018 PDT|    13| 1.5|     
Sun Jul 01 07:01:00 2018 PDT|    13| 1.4|     
Sun Jul 01 09:11:00 2018 PDT|    90| 2.7|     
Sun Jul 01 09:21:00 2018 PDT|    90| 2.8|     
Sun Sep 03 06:18:00 2017 PDT|     9| 8.7|    3
(9 rows)


NOTICE:  [db_dist_hypertable_2]: 
SELECT * FROM disttable
NOTICE:  [db_dist_hypertable_2]:
time                        |device|temp|Color
----------------------------+------+----+-----
Sun Jan 01 09:11:00 2017 PST|     3| 2.1|     
Sun Jan 01 09:21:00 2017 PST|     3| 2.2|     
Sun Jan 01 08:11:00 2017 PST|     3| 2.3|     
Mon Jan 02 08:01:00 2017 PST|     2| 1.3|     
Mon Jan 02 09:01:00 2017 PST|     2| 1.4|     
Mon Jan 02 08:21:00 2017 PST|     2| 1.5|     
Mon Jul 02 08:01:00 2018 PDT|    87| 1.6|     
Mon Jul 02 09:01:00 2018 PDT|    87| 1.4|     
Mon Jul 02 09:21:00 2018 PDT|    87| 1.8|     
Sun Jul 01 08:01:00 2018 PDT|    29| 1.5|     
Sun Jul 01 08:21:00 2018 PDT|    29| 1.2|     
Sat Sep 02 06:09:00 2017 PDT|     4| 9.8|    1
(12 rows)


NOTICE:  [db_dist_hypertable_3]: 
SELECT * FROM disttable
NOTICE:  [db_dist_hypertable_3]:
time                        |device|temp|Color
----------------------------+------+----+-----
Sat Sep 02 06:09:00 2017 PDT|     6|10.5|    2
(1 row)


 remote_exec 
-------------
 
(1 row)

\set ON_ERROR_STOP 0
-- ON CONFLICT DO NOTHING only works when index inference is omitted
\set VERBOSITY default
INSERT INTO disttable
VALUES ('2017-09-02 06:09', 6)
ON CONFLICT(time,device) DO NOTHING;
ERROR:  could not find arbiter index for hypertable index "disttable_pkey" on chunk "_dist_hyper_1_10_chunk"
HINT:  Omit the index inference specification for the distributed hypertable in the ON CONFLICT clause.
INSERT INTO disttable
VALUES ('2017-09-02 06:09', 6)
ON CONFLICT(time,device,"Color") DO NOTHING;
ERROR:  could not find arbiter index for hypertable index "disttable_color_unique" on chunk "_dist_hyper_1_10_chunk"
HINT:  Omit the index inference specification for the distributed hypertable in the ON CONFLICT clause.
INSERT INTO disttable
VALUES ('2017-09-02 06:09', 6)
ON CONFLICT ON CONSTRAINT disttable_color_unique DO NOTHING;
ERROR:  could not find arbiter index for hypertable index "disttable_color_unique" on chunk "_dist_hyper_1_10_chunk"
HINT:  Omit the index inference specification for the distributed hypertable in the ON CONFLICT clause.
\set VERBOSITY terse
SELECT * FROM disttable ORDER BY disttable;
             time             | device | temp | Color 
------------------------------+--------+------+-------
 Sun Jan 01 06:01:00 2017 PST |      1 |  1.1 |      
 Sun Jan 01 06:05:00 2017 PST |      1 |  1.4 |      
 Sun Jan 01 08:01:00 2017 PST |      1 |  1.2 |      
 Sun Jan 01 08:11:00 2017 PST |      3 |  2.3 |      
 Sun Jan 01 09:11:00 2017 PST |      3 |  2.1 |      
 Sun Jan 01 09:21:00 2017 PST |      3 |  2.2 |      
 Mon Jan 02 08:01:00 2017 PST |      2 |  1.3 |      
 Mon Jan 02 08:21:00 2017 PST |      2 |  1.5 |      
 Mon Jan 02 09:01:00 2017 PST |      2 |  1.4 |      
 Sat Sep 02 06:09:00 2017 PDT |      4 |  9.8 |     1
 Sat Sep 02 06:09:00 2017 PDT |      6 | 10.5 |     2
 Sun Sep 03 06:18:00 2017 PDT |      9 |  8.7 |     3
 Sun Jul 01 06:01:00 2018 PDT |     13 |  1.4 |      
 Sun Jul 01 06:21:00 2018 PDT |     13 |  1.5 |      
 Sun Jul 01 07:01:00 2018 PDT |     13 |  1.4 |      
 Sun Jul 01 08:01:00 2018 PDT |     29 |  1.5 |      
 Sun Jul 01 08:21:00 2018 PDT |     29 |  1.2 |      
 Sun Jul 01 09:11:00 2018 PDT |     90 |  2.7 |      
 Sun Jul 01 09:21:00 2018 PDT |     90 |  2.8 |      
 Mon Jul 02 08:01:00 2018 PDT |     87 |  1.6 |      
 Mon Jul 02 09:01:00 2018 PDT |     87 |  1.4 |      
 Mon Jul 02 09:21:00 2018 PDT |     87 |  1.8 |      
(22 rows)

-- ON CONFLICT only works with DO NOTHING for now
INSERT INTO disttable (time, device, "Color", temp)
VALUES ('2017-09-09 08:13', 7, 3, 27.5)
ON CONFLICT (time) DO UPDATE SET temp = 3.2;
ERROR:  ON CONFLICT DO UPDATE not supported on distributed hypertables
-- Test that an INSERT that would create a chunk does not work on a
-- data node
SELECT * FROM test.remote_exec(ARRAY[:'DATA_NODE_1'], $$
    INSERT INTO disttable VALUES ('2019-01-02 12:34', 1, 2, 9.3)
$$);
NOTICE:  [db_dist_hypertable_1]: 
    INSERT INTO disttable VALUES ('2019-01-02 12:34', 1, 2, 9.3)

ERROR:  [db_dist_hypertable_1]: distributed hypertable member cannot create chunk on its own
\set ON_ERROR_STOP 1
-- However, INSERTs on a data node that does not create a chunk works.
SELECT * FROM test.remote_exec(ARRAY[:'DATA_NODE_1'], $$
    INSERT INTO disttable VALUES ('2017-09-03 06:09', 1, 2, 9.3)
$$);
NOTICE:  [db_dist_hypertable_1]: 
    INSERT INTO disttable VALUES ('2017-09-03 06:09', 1, 2, 9.3)

ERROR:  [db_dist_hypertable_1]: distributed hypertable member cannot create chunk on its own

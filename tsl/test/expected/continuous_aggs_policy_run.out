-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
-- The tests in this file use mock timestamps to test policies
-- for timestamp based tables and can be run only with debug builds.
SET ROLE :ROLE_DEFAULT_PERM_USER;
--- code coverage tests : add policy for timestamp and date based table ---
CREATE TABLE continuous_agg_max_mat_date(time DATE);
SELECT create_hypertable('continuous_agg_max_mat_date', 'time');
NOTICE:  adding not-null constraint to column "time"
            create_hypertable             
------------------------------------------
 (1,public,continuous_agg_max_mat_date,t)
(1 row)

CREATE MATERIALIZED VIEW max_mat_view_date
    WITH (timescaledb.continuous, timescaledb.materialized_only=true)
    AS SELECT time_bucket('1 days', time), count(*)
        FROM continuous_agg_max_mat_date
        GROUP BY 1 WITH NO DATA;
SELECT add_continuous_aggregate_policy('max_mat_view_date', '3 days', '1 day', '1 day'::interval) as job_id \gset
SELECT config FROM _timescaledb_config.bgw_job
WHERE id = :job_id;
                                    config                                     
-------------------------------------------------------------------------------
 {"end_offset": "@ 1 day", "start_offset": "@ 3 days", "mat_hypertable_id": 2}
(1 row)

INSERT INTO continuous_agg_max_mat_date
    SELECT generate_series('2019-09-01'::date, '2019-09-10'::date, '1 day');
--- to prevent NOTICES set message level to warning
SET client_min_messages TO warning; 
SET timescaledb.current_timestamp_mock = '2019-09-10 00:00';
CALL run_job(:job_id);
SELECT * FROM max_mat_view_date order by 1;
 time_bucket | count 
-------------+-------
 09-07-2019  |     1
 09-08-2019  |     1
(2 rows)

RESET client_min_messages ;
DROP MATERIALIZED VIEW max_mat_view_date;
NOTICE:  drop cascades to table _timescaledb_internal._hyper_2_3_chunk
CREATE TABLE continuous_agg_timestamp(time TIMESTAMP);
SELECT create_hypertable('continuous_agg_timestamp', 'time');
NOTICE:  adding not-null constraint to column "time"
           create_hypertable           
---------------------------------------
 (3,public,continuous_agg_timestamp,t)
(1 row)

CREATE MATERIALIZED VIEW max_mat_view_timestamp
    WITH (timescaledb.continuous, timescaledb.materialized_only=true)
    AS SELECT time_bucket('7 days', time), count(*)
        FROM continuous_agg_timestamp
        GROUP BY 1 WITH NO DATA;
SELECT add_continuous_aggregate_policy('max_mat_view_timestamp', '15 days', '1 h'::interval , '1 h'::interval) as job_id \gset
INSERT INTO continuous_agg_timestamp
    SELECT generate_series('2019-09-01 00:00'::timestamp, '2019-09-10 00:00'::timestamp, '1 day');
--- to prevent NOTICES set message level to warning
SET client_min_messages TO warning; 
SET timescaledb.current_timestamp_mock = '2019-09-11 00:00';
CALL run_job(:job_id);
SELECT * FROM max_mat_view_timestamp;
       time_bucket        | count 
--------------------------+-------
 Mon Sep 02 00:00:00 2019 |     7
(1 row)

RESET client_min_messages ;
-- Check that running compression job after new data has been inserted
-- works.
CREATE TABLE sensor_data(
    time timestamptz not null,
    sensor_id integer not null,
    cpu double precision null,
    temperature double precision null
);
SELECT * FROM create_hypertable('sensor_data','time');
 hypertable_id | schema_name | table_name  | created 
---------------+-------------+-------------+---------
             5 | public      | sensor_data | t
(1 row)

INSERT INTO sensor_data
SELECT time + (INTERVAL '1 minute' * random()) AS time,
       sensor_id,
       random() AS cpu,
       random()* 100 AS temperature
FROM generate_series(now() - INTERVAL '1 months', now() - INTERVAL '1 week', INTERVAL '10 minute') AS g1(time),
     generate_series(1, 100, 1 ) AS g2(sensor_id)
ORDER BY time;
ALTER TABLE sensor_data SET (timescaledb.compress, timescaledb.compress_orderby = 'time DESC');
SELECT add_compression_policy('sensor_data','1 minute'::INTERVAL) as job_id \gset
CALL run_job(:job_id);
NOTICE:  no chunks for hypertable public.sensor_data that satisfy compress chunk policy
-- Verify that chunks are compressed
SELECT c.chunk_name,c.range_start,c.range_end,c.is_compressed
  FROM public.chunks_detailed_size('public.sensor_data')
  JOIN timescaledb_information.chunks
 USING (chunk_name)
 ORDER BY c.range_start;
ERROR:  missing FROM-clause entry for table "c" at character 8
